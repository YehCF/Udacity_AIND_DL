{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyzing IMDB Data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Loading the data\n",
    "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Lading the data (it's preloaded in Keras)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Examining the data\n",
    "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
    "\n",
    "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. One-hot encoding the output\n",
    "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (25000, 1000)\n",
      "[ 0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output into vector mode, each of length 1000\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print(\"Shape of x_train:\",x_train.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And we'll also one-hot encode the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Building the  model architecture\n",
    "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 685,122.0\n",
      "Trainable params: 685,122.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "# Build the model architecture\n",
    "model = Sequential()\n",
    "#model.add(Dense(2048, input_shape=(1000,)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "#model.add(Dense(1024, kernel_regularizer=regularizers.l2(1e-4)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "model.add(Dense(512, input_shape=(1000,), kernel_regularizer=regularizers.l2(1e-2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(256, kernel_regularizer=regularizers.l2(1e-2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(1e-2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64, kernel_regularizer=regularizers.l2(1e-2)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Compile the model using a loss function and an optimizer.\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Training the model\n",
    "Run the model here. Experiment with different batch_size, and number of epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "10s - loss: 4.4157 - acc: 0.7369 - val_loss: 2.5560 - val_acc: 0.8174\n",
      "Epoch 2/30\n",
      "9s - loss: 2.3952 - acc: 0.7672 - val_loss: 2.0793 - val_acc: 0.8402\n",
      "Epoch 3/30\n",
      "9s - loss: 2.0099 - acc: 0.8194 - val_loss: 1.8396 - val_acc: 0.8344\n",
      "Epoch 4/30\n",
      "10s - loss: 1.8460 - acc: 0.8091 - val_loss: 1.6807 - val_acc: 0.8368\n",
      "Epoch 5/30\n",
      "10s - loss: 1.7011 - acc: 0.7964 - val_loss: 1.5064 - val_acc: 0.8440\n",
      "Epoch 6/30\n",
      "11s - loss: 1.4831 - acc: 0.8300 - val_loss: 1.3573 - val_acc: 0.8512\n",
      "Epoch 7/30\n",
      "9s - loss: 1.3055 - acc: 0.8433 - val_loss: 1.2686 - val_acc: 0.8192\n",
      "Epoch 8/30\n",
      "9s - loss: 1.1803 - acc: 0.8407 - val_loss: 1.4287 - val_acc: 0.5196\n",
      "Epoch 9/30\n",
      "10s - loss: 1.2316 - acc: 0.8080 - val_loss: 1.0854 - val_acc: 0.8480\n",
      "Epoch 10/30\n",
      "12s - loss: 1.0236 - acc: 0.8473 - val_loss: 0.9340 - val_acc: 0.8508\n",
      "Epoch 11/30\n"
     ]
    }
   ],
   "source": [
    "# Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=64, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1527f00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the training loss and validation loss\n",
    "plt.plot(history.history[\"loss\"], color='b')\n",
    "plt.plot(history.history[\"val_loss\"], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Evaluating the model\n",
    "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.83824\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model\n",
    "<ul>\n",
    "<li>Current Best One</li>\n",
    "    <ul>\n",
    "    <li>Test Accuracy: 0.85104</li>\n",
    "    <li>Architecture: <br> 4 fully-connected hidden layers (nodes: 512, 256, 128, 64) + 1 fully-connected layer for logits (nodes:2)</li>\n",
    "    <li>Hyperparameters: <br> learning rate (1e-4), batch size (128), epoch (30)</li>\n",
    "    <li>Ways to prevent overfitting: <br> L2-regularization (penalty:1e-4) <br> Dropout rate (0.5)\n",
    "    </li>\n",
    "    </ul>\n",
    "<li>First Try</li>\n",
    "    <ul>\n",
    "    <li>Architecture: <br> 6 fully-connected layers (nodes: 2048, 1024, 512, 256, 128, 64) + 1 fully-connected layer for logits</li>\n",
    "    <li>Result</li>\n",
    "        <ul>\n",
    "        <li>It took 30s to run an epoch (not efficient) although it reach 80% validation accuracy at first epoch</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "<li>How to tune it to the current one</li>\n",
    "    <ul>\n",
    "        <li>Try to modify the first layer (nodes: 2048, 1024 or 512)\n",
    "        <br>It turns out that node-512 is a good choice considering the efficency\n",
    "        </li>\n",
    "        <li>Add dropout rate\n",
    "        <br>At first, I try with rate 0.5. Then tune to 0.1, 0.3 if the model starts underfitting. Tune back to 0.5 or even 0.7 if overfitting.\n",
    "        </li>\n",
    "        <li>Add L2-Regularization\n",
    "        <br>Start with 1e-4. If model starts overfitting, increase to 1e-2. If the model starts underfitting, consider tune back to 1e-4 or even 1e-5.\n",
    "        </li>\n",
    "        <li>How about Optimizer:\n",
    "        <br>In this case, I also tried Adagrad and SGD, but it seemed that Adam (with default parameters) always did well in what I've tried.\n",
    "        </li>\n",
    "        <li>How about other hyper-parameters?\n",
    "        <br>At some architectures, it only needs 10 epochs to get validation accuracy nearly 85%. After adding L2-regularization and increase dropout rate, it would take around 20% to get a stable validation accuracy 85%.\n",
    "        <br>Set batch size to 128 or 64 can get good result at first few epochs.\n",
    "        </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
